# -*- coding: utf-8 -*-
"""RAG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZN_t0pqc5jJifQxnEXh3WgqjHOeVTDdi
"""

!pip install langchain langchain_openai chromadb streamlit unstructured python-pptx python-docx pypdf google-colab google-auth-oauthlib google-auth-httplib2 google-api-python-client langchain_community PyMuPDF docx2txt

!pip install tenacity

!apt-get update && apt-get install -y google-cloud-sdk

!gcloud auth login

!gcloud config set project daclub-session-1

!apt-get install docker.io

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# langchain
# langchain_openai
# chromadb
# unstructured
# python-pptx
# python-docx
# pypdf
# google-colab
# google-auth-oauthlib
# google-auth-httplib2
# google-api-python-client
# langchain_community

import os
import tempfile
import streamlit as st
from google.colab import drive
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from tenacity import retry, stop_after_attempt, wait_exponential
import io
import pickle
import base64
from typing import List, Tuple
import fitz # import PyMuPDF as fitz
import docx2txt

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.schema import Document
from langchain.chains import ConversationalRetrievalChain

import pypdf
from pptx import Presentation
from docx import Document

# Configuration
FOLDER_ID = "1rhYI8LHlPWXj9ZzOC02FrjIwvLM-eMrQ"
OPENAI_API_KEY = "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"

# Mount Google Drive
from google.colab import drive # Import the drive function from google.colab module
drive.mount('/content/drive')

# Google Drive setup
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']

from google.oauth2 import service_account

from googleapiclient.discovery import build

def authenticate_with_service_account():
    credentials = service_account.Credentials.from_service_account_file(
                'service_account.json',
    scopes=['https://www.googleapis.com/auth/drive.readonly']
    )
    service = build('drive', 'v3', credentials=credentials)
    return service

from typing import List, Tuple

def download_files_from_folder(service, folder_id: str) -> List[Tuple[str, bytes]]:
    results = service.files().list(
        q=f"'{folder_id}' in parents",
        fields="files(id, name, mimeType)").execute()
    files = results.get('files', [])

    downloaded_files = []
    for file in files:
        request = service.files().get_media(fileId=file['id'])
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
        downloaded_files.append((file['name'], fh.getvalue()))

    return downloaded_files

def process_file(file_name: str, content: bytes) -> str:
    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        temp_file.write(content)
        temp_path = temp_file.name

    text = ""
    if file_name.endswith('.pdf'):
        # Use PyMuPDF to extract text from PDFs
        doc = fitz.open(temp_path)
        for page in doc:
            text += page.get_text()

    elif file_name.endswith('.docx'):
        # Use docx2txt to extract text from DOCX files
        text = docx2txt.process(temp_path)

    elif file_name.endswith('.pptx'):
        prs = Presentation(temp_path)
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"

    os.unlink(temp_path)
    return text

def initialize_qa_system():
    """Initialize the QA system with the configured folder and API key"""
    service = authenticate_with_service_account()

    # Initialize OpenAI components
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) # This is the embedding model
    llm = ChatOpenAI(
        temperature=0,
        openai_api_key=OPENAI_API_KEY,
        model="gpt-4-turbo-1106"
    )

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=1, max=10))
    def embed_with_retry(texts):
        return embeddings.embed_documents(texts)  # Call embed_documents on the embeddings object


    # Download and process files
    service = authenticate_with_service_account()
    results = service.files().list(
        q=f"'{FOLDER_ID}' in parents",
        fields="files(id, name, mimeType)").execute()
    files = results.get('files', [])

    print(f"Files found: {files}")  # Print the list of files found

    all_text = ""
    for file in files:
        # Download file content
        request = service.files().get_media(fileId=file['id'])
        fh = io.BytesIO() # Define fh here to store file content
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
            print(f"Download {int(status.progress() * 100)}.")
        all_text += process_file(file['name'], fh.getvalue()) + "\n\n"

    print(f"All text length: {len(all_text)}")  # Print the length of the extracted text

# In initialize_qa_system() function:
   # Reduce chunk_size to create fewer chunks and thus fewer API calls for embedding
    text_splitter = RecursiveCharacterTextSplitter(
       chunk_size=1000,
       chunk_overlap=200,
       length_function=len
    )
    texts = text_splitter.create_documents([all_text])

    # Create vector store, using embed_with_retry for embedding
    vectorstore = Chroma.from_documents(
        documents=texts,
        embedding=embeddings, # Pass the embeddings object here, not the function
        persist_directory="chroma_db"
    )

    # Set up retriever with reranking
    base_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    compressor = LLMChainExtractor.from_llm(llm)
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=compressor,
        base_retriever=base_retriever
    )

    # Create conversational chain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=compression_retriever,
        return_source_documents=True,
        verbose=True
    )

    return qa_chain

import streamlit as st # This line imports the streamlit library as 'st'
import base64 # Import the base64 module

def add_logo():
    # Replace this with your actual logo as a base64 string
    logo_svg = '''
    <svg width="100" height="100" viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
        <rect x="20" y="20" width="60" height="60" fill="#4A90E2"/>
        <circle cx="50" cy="50" r="25" fill="white"/>
        <text x="50" y="55" font-family="Arial" font-size="14" fill="#4A90E2" text-anchor="middle">RAG</text>
    </svg>
    '''

    b64 = base64.b64encode(logo_svg.encode('utf-8')).decode()

    st.markdown(
        f"""
        <style>
            [data-testid="stHeader"] {{
                background-color: white;
            }}

            .logo-container {{
                display: flex;
                justify-content: center;
                margin-bottom: 2rem;
            }}

            .chat-container {{
                max-width: 800px;
                margin: 0 auto;
                padding: 2rem;
            }}

            .stChatMessage {{
                background-color: #ffffff;
                border-radius: 10px;
                padding: 1rem;
                margin: 0.5rem 0;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
        </style>
        <div class="logo-container">
            <img src="data:image/svg+xml;base64,{b64}" alt="Logo" width="100">
        </div>
        """,
        unsafe_allow_html=True
    )

import streamlit as st

def main():
    st.set_page_config(page_title="Document Q&A System", layout="wide")
    add_logo()

    st.markdown('<h1 style="text-align: center;">Ask me anything about the fund</h1>', unsafe_allow_html=True)

    # Initialize the QA system if not already done
    if "qa_chain" not in st.session_state:
        with st.spinner("Initializing the system..."):
            st.session_state.qa_chain = initialize_qa_system() # Assuming this function is defined elsewhere
            st.session_state.chat_history = []

    # Chat interface
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("What would you like to know?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response = st.session_state.qa_chain(
                {"question": prompt, "chat_history": st.session_state.chat_history}
            )
            st.markdown(response["answer"])
            st.session_state.messages.append({"role": "assistant", "content": response["answer"]})
            st.session_state.chat_history.append((prompt, response["answer"]))

    st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# langchain
# langchain_openai
# chromadb
# unstructured
# python-pptx
# python-docx
# pypdf
# google-colab
# google-auth-oauthlib
# google-auth-httplib2
# google-api-python-client
# langchain_community

from pyngrok import ngrok

# Kill any existing ngrok processes
!pkill ngrok

# Establish a new ngrok connection
public_url = ngrok.connect(addr="8501")
print(f"Public URL: {public_url}")

# Now run your Streamlit app using the public_url
# (Replace with your actual command to run Streamlit)
!streamlit run /content/drive/MyDrive/IR_RAG/rag.py --server.address 0.0.0.0 --server.port 8501